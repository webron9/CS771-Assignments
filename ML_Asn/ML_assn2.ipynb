{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE, ADASYN,SVMSMOTE"
      ],
      "metadata": {
        "id": "t0SHQ2gFfNYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeXF5wNJ7-jR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import random as rand\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# DO NOT CHANGE THE NAME OF THIS METHOD OR ITS INPUT OUTPUT BEHAVIOR\n",
        "\n",
        "# PLEASE BE CAREFUL THAT ERROR CLASS NUMBERS START FROM 1 AND NOT 0. THUS, THE FIFTY ERROR CLASSES ARE\n",
        "# NUMBERED AS 1 2 ... 50 AND NOT THE USUAL 0 1 ... 49. PLEASE ALSO NOTE THAT ERROR CLASSES 33, 36, 38\n",
        "# NEVER APPEAR IN THE TRAINING SET NOR WILL THEY EVER APPEAR IN THE SECRET TEST SET (THEY ARE TOO RARE)\n",
        "\n",
        "# Input Convention\n",
        "# X: n x d matrix in csr_matrix format containing d-dim (sparse) bag-of-words features for n test data points\n",
        "# k: the number of compiler error class guesses to be returned for each test data point in ranked order\n",
        "\n",
        "\n",
        "# Output Convention\n",
        "# The method must return an n x k numpy nd-array (not numpy matrix or scipy matrix) of classes with the i-th row\n",
        "# containing k error classes which it thinks are most likely to be the correct error class for the i-th test point.\n",
        "# Class numbers must be returned in ranked order i.e. the label yPred[i][0] must be the best guess for the error class\n",
        "# for the i-th data point followed by yPred[i][1] and so on.\n",
        "\n",
        "# CAUTION: Make sure that you return (yPred below) an n x k numpy nd-array and not a numpy/scipy/sparse matrix\n",
        "# Thus, the returned matrix will always be a dense matrix. The evaluation code may misbehave and give unexpected\n",
        "# results if an nd-array is not returned. Please be careful that classes are numbered from 1 to 50 and not 0 to 49.\n",
        "\n",
        "def findErrorClass( X, k ):\n",
        "\t# Find out how many data points we have\n",
        "\tn = X.shape[0]\n",
        "\t# Load and unpack a dummy model to see an example of how to make predictions\n",
        "\t# The dummy model simply stores the error classes in decreasing order of their popularity\n",
        "\tnpzModel = np.load( \"model.npz\" )\n",
        "\tmodel = npzModel[npzModel.files[0]]\n",
        "\t# Let us predict a random subset of the 2k most popular labe\n",
        "\t# ls no matter what the test point\n",
        "\tshortList = model[0:2*k]\n",
        "\t# Make sure we are returning a numpy nd-array and not a numpy matrix or a scipy sparse matrix\n",
        "\tyPred = np.zeros( (n, k) )\n",
        "\tfor i in range( n ):\n",
        "\t\tyPred[i,:] = rand.permutation( shortList )[0:k]\n",
        "\n",
        "\treturn yPred"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "from sklearn.datasets import dump_svmlight_file\n",
        "from scipy import sparse as sps"
      ],
      "metadata": {
        "id": "yHI1vPMi8FhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def loadData( filename, dictSize = 225 ):\n",
        "\tX, y = load_svmlight_file( filename, multilabel = False, n_features = dictSize, offset = 1 )\n",
        "\treturn (X, y)\n",
        "\n",
        "def dumpData( X, y, filename ):\n",
        "\t(n, d) = X.shape\n",
        "\tassert len(y) == n, \"Mismatch in number of feature vectors and number of label vectors\"\n",
        "\tdump_svmlight_file( X, y, filename, multilabel = False, zero_based = True, comment = \"%d, %d\" % (n, d) )\n",
        "\n",
        "# Not the best way to do things in Python but I could not find a neater workaround\n",
        "# Let me know if you know one that avoids a messy loop\n",
        "def removeDuplicates( pred, imputation ):\n",
        "\t# Create a new array so that the original input array pred is unaffected\n",
        "\tdeDup = np.ones( pred.shape ) * imputation\n",
        "\tfor i in range( pred.shape[0] ):\n",
        "\t\t# Retain only the first occurrence of a label in every row\n",
        "\t\t(u, idx) = np.unique( pred[i,:], return_index = True )\n",
        "\t\tdeDup[i,idx] = u\n",
        "\treturn deDup\n",
        "\n",
        "# Validate that data is nice and well behaved\n",
        "# Return a copy of the predicted error classes that removes duplicates\n",
        "# The original data is not affected i.e. this method can be called repeatedly\n",
        "# Also return a one-hot representation of the gold labels for easier processing\n",
        "# without affecting the arguments sent as inputs\n",
        "def validateAndCleanup( yGold, yPred, k ):\n",
        "\tn = len(yGold)\n",
        "\n",
        "\t# Make sure the prediction matrix is in correct shape\n",
        "\tassert yPred.shape[0] == n, \"Mismatch in number of test data points and number of predictions\"\n",
        "\tassert yPred.shape[1] == k, \"Mismatch in number of predictions received and number expected\"\n",
        "\n",
        "\t# Penalize duplicates in yPred by replacing them with predictions of the dummy error class 0\n",
        "\t# Since error classes are numbered from 1 to 50, the 0 error class is a safe dummy choice\n",
        "\tyPredNew = removeDuplicates( yPred, 0 )\n",
        "\n",
        "\t# Need to convert the gold labels into a one-hot representation to make things easier later on\n",
        "\tyGoldNew = np.zeros( (n, 50) )\n",
        "\t# The -1 step is required since gold labels are indexed 1 ... 50 whereas Python expects zero_based indices\n",
        "\tyGoldNew[ np.arange(n), yGold[:,np.newaxis].astype(int).T - 1 ] = 1\n",
        "\n",
        "\treturn (yGoldNew, yPredNew)\n",
        "\n",
        "# For a given value of k, return prec@1, prec@2, ..., prec@k\n",
        "def getPrecAtK( yGold, yPred, k ):\n",
        "\tn = len(yGold)\n",
        "\t(yGoldNew, yPredNew) = validateAndCleanup( yGold, yPred, k )\n",
        "\n",
        "\t# Use some fancy indexing (yes, this is the formal term for the technique)\n",
        "\t# to find out where all did we predict the correct error class\n",
        "\t# Python indexing with arrays creates copies of data so we are safe\n",
        "\t# The -1 step is required since predicted labels are indexed 1 ... 50 whereas Python expects zero_based indices\n",
        "\twins = yGoldNew[ np.arange( n )[:,np.newaxis], yPredNew.astype(int) - 1 ]\n",
        "\n",
        "\t# Find how many times did we correctly predict the correct class at the blah-th position\n",
        "\ttotWins = np.sum( wins, axis = 0 )\n",
        "\t# Find how many times did we correctly predict the correct class at any one of the top blah positions\n",
        "\tcumWins = np.cumsum( totWins )\n",
        "\n",
        "\t# Normalize and return\n",
        "\tprecAtK = cumWins / n\n",
        "\treturn precAtK\n",
        "\n",
        "# For a given value of k, return mprec@1, mprec@2, ..., mprec@k\n",
        "def getMPrecAtK( yGold, yPred, k ):\n",
        "\tC = 50 # There are 50 error classes\n",
        "\tCEff = 0 # Number of classes that actually have a presence in the test data\n",
        "\t(yGoldNew, yPredNew) = validateAndCleanup( yGold, yPred, k )\n",
        "\tmPrecAtK = np.zeros( k )\n",
        "\n",
        "\t# For all real error classes (exclude the dummy error class)\n",
        "\tfor cls in range( C ):\n",
        "\t\t# Find data points for which this is the error class\n",
        "\t\tpointsWithThisErrorClass = (yGoldNew[:, cls] == 1).reshape( -1 )\n",
        "\t\tn_cls = np.sum( yGoldNew[:, cls] )\n",
        "\n",
        "\t\t# If there exist data points for which this is the correct error class\n",
        "\t\tif n_cls > 0:\n",
        "\t\t\t# Find all data points for which this class was predicted\n",
        "\t\t\t# Create a new array so that the array yPredNew is unaffected since it has to be reused\n",
        "\t\t\t# The +1 is required since the counter cls runs from 0 to 49 whereas the predictions are from 1 to 50\n",
        "\t\t\twinsThisClass = np.zeros( yPredNew.shape )\n",
        "\t\t\twinsThisClass[ yPredNew == cls + 1 ] = 1\n",
        "\t\t\t# Remove cases of data points for which this is not the correct error class\n",
        "\t\t\twinsThisClass[ ~pointsWithThisErrorClass, : ] = 0\n",
        "\t\t\t# How many times did we correctly predict this error class at the blah-th position?\n",
        "\t\t\ttotWinsThisClass = np.sum( winsThisClass, axis = 0 )\n",
        "\t\t\t# Find how many times did we correctly predict this error class at any one of the top blah positions\n",
        "\t\t\tcumWins = np.cumsum( totWinsThisClass )\n",
        "\t\t\t# Add the wins to mprec@blah\n",
        "\t\t\tmPrecAtK += cumWins / n_cls\n",
        "\t\t\tCEff += 1\n",
        "\treturn mPrecAtK / CEff\n"
      ],
      "metadata": {
        "id": "vOa7vX2X8Lv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time as tm\n",
        "\n",
        "# This file is intended to demonstrate how we would evaluate your codeP\n",
        "# The data loader needs to know how many feature dimensions are there\n",
        "dictSize = 225\n",
        "(X, y) = loadData( \"train\", dictSize = dictSize )\n",
        "\n",
        "# Get error class predictions from predict.py and time the thing\n",
        "tic = tm.perf_counter()\n",
        "yPred = findErrorClass( X, 5 )\n",
        "toc = tm.perf_counter()\n",
        "\n",
        "print( \"Total time taken is %.6f seconds \" % (toc - tic) )\n",
        "\n",
        "preck = getPrecAtK( y, yPred, 5 )\n",
        "# The macro precision code takes a bit longer to execute due to the for loop over labels\n",
        "mpreck = getMPrecAtK( y, yPred, 5 )\n",
        "\n",
        "# According to our definitions, both prec@k and mprec@k should go up as k goes up i.e. for your\n",
        "# method, prec@i > prec@j if i > j and mprec@i > mprec@j if i > j. See the assignment description\n",
        "# to convince yourself why this must be the case.\n",
        "\n",
        "print( \"prec@1: %0.3f\" % preck[0], \"prec@3: %0.3f\" % preck[2], \"prec@5: %0.3f\" % preck[4] )\n",
        "# Dont be surprised if mprec is small -- it is hard to do well on rare error classes\n",
        "print( \"mprec@1: %0.3e\" % mpreck[0], \"mprec@3: %0.3e\" % mpreck[2], \"mprec@5: %0.3e\" % mpreck[4] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM7dw2mO8vWh",
        "outputId": "0d7f7f5b-247a-4f3f-e776-f185b977e4bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time taken is 0.042576 seconds \n",
            "prec@1: 0.086 prec@3: 0.256 prec@5: 0.426\n",
            "mprec@1: 2.047e-02 mprec@3: 6.412e-02 mprec@5: 1.070e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = loadData(\"train\",225)\n",
        "print(X.shape,y.shape)"
      ],
      "metadata": {
        "id": "EGKitW9A8OyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5fe864c-bdbc-4606-fe05-94fe68bf2dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 225) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0,stratify=y)\n",
        "print(X_train.shape,X_test.shape)\n",
        "X, y = SMOTE(k_neighbors = 1).fit_resample(X_train, y_train)\n",
        "print(X.shape,y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di7m7PN58Pk8",
        "outputId": "25614d76-e4a4-4113-f492-470fe2567234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7500, 225) (2500, 225)\n",
            "(90193, 225) (90193,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LogReg = LogisticRegression(random_state=0,max_iter=1000).fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "nrKpI42e8Q3z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "690904b9-c731-46b4-e2c8-50f848da596e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-f8f850f22d48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLogReg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1612\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             )\n\u001b[0;32m-> 1614\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m         )\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 289\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 289\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    810\u001b[0m                 \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m                 \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"iprint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m             )\n\u001b[1;32m    814\u001b[0m             n_iter_i = _check_optimize_result(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 624\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    625\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    351\u001b[0m         _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n\u001b[1;32m    352\u001b[0m                        \u001b[0mpgtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miwa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsave\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                        isave, dsave, maxls)\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0mtask_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'FG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = LogReg.predict(X_train)\n",
        "print(y_pred.shape)"
      ],
      "metadata": {
        "id": "LVmqX74a81x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "2nN5pLOx9H3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy_score(y_train, y_pred)\n",
        "acc"
      ],
      "metadata": {
        "id": "aXR0w2ag95pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = LogReg.predict(X_test)\n",
        "acc2 = accuracy_score(y_test,y_pred_test)\n",
        "print(acc2)"
      ],
      "metadata": {
        "id": "zvxkvWtU-CBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.sparse as sparse\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "VSd7cgp3_EES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = {}\n",
        "for i in y:\n",
        "  if i in count:\n",
        "    count[i] += 1\n",
        "  else:\n",
        "    count[i] = 1\n",
        "print(count)\n",
        "count_fin = sorted(count.items(), key=lambda kv:(kv[1], kv[0]))[::-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brKjSuUNJR6e",
        "outputId": "2026fa71-16b1-4ff6-a85e-c6a4e82711d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1.0: 1919, 4.0: 1919, 3.0: 1919, 37.0: 1919, 5.0: 1919, 24.0: 1919, 2.0: 1919, 32.0: 1919, 9.0: 1919, 21.0: 1919, 7.0: 1919, 10.0: 1919, 8.0: 1919, 12.0: 1919, 29.0: 1919, 45.0: 1919, 35.0: 1919, 19.0: 1919, 48.0: 1919, 17.0: 1919, 13.0: 1919, 31.0: 1919, 30.0: 1919, 23.0: 1919, 20.0: 1919, 43.0: 1919, 15.0: 1919, 39.0: 1919, 11.0: 1919, 22.0: 1919, 18.0: 1919, 28.0: 1919, 16.0: 1919, 25.0: 1919, 50.0: 1919, 6.0: 1919, 26.0: 1919, 42.0: 1919, 47.0: 1919, 41.0: 1919, 40.0: 1919, 34.0: 1919, 49.0: 1919, 44.0: 1919, 46.0: 1919, 14.0: 1919, 27.0: 1919}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dic = dict(sorted(count.items(), key=lambda item: item[1], reverse=True))\n",
        "print(test_dic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj_UijhSHfhJ",
        "outputId": "a23229df-bb1f-4e56-af36-dd5694092b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1.0: 1919, 4.0: 1919, 3.0: 1919, 37.0: 1919, 5.0: 1919, 24.0: 1919, 2.0: 1919, 32.0: 1919, 9.0: 1919, 21.0: 1919, 7.0: 1919, 10.0: 1919, 8.0: 1919, 12.0: 1919, 29.0: 1919, 45.0: 1919, 35.0: 1919, 19.0: 1919, 48.0: 1919, 17.0: 1919, 13.0: 1919, 31.0: 1919, 30.0: 1919, 23.0: 1919, 20.0: 1919, 43.0: 1919, 15.0: 1919, 39.0: 1919, 11.0: 1919, 22.0: 1919, 18.0: 1919, 28.0: 1919, 16.0: 1919, 25.0: 1919, 50.0: 1919, 6.0: 1919, 26.0: 1919, 42.0: 1919, 47.0: 1919, 41.0: 1919, 40.0: 1919, 34.0: 1919, 49.0: 1919, 44.0: 1919, 46.0: 1919, 14.0: 1919, 27.0: 1919}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wts = {}\n",
        "tot_samples = 10000\n",
        "j = 0\n",
        "for i in range(50):\n",
        "  if i == 32 or i == 35 or i == 37:\n",
        "    #weights[float(i+1)] = 1\n",
        "    pass\n",
        "  else:\n",
        "    wts[float(j+1)] = tot_samples/(50*(count[float(j+1)]))\n",
        "  j += 1\n",
        "print(wts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RbccLGfQzJK",
        "outputId": "a9c4e648-131d-47ef-acc6-92f22540a79e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1.0: 0.10422094841063054, 2.0: 0.10422094841063054, 3.0: 0.10422094841063054, 4.0: 0.10422094841063054, 5.0: 0.10422094841063054, 6.0: 0.10422094841063054, 7.0: 0.10422094841063054, 8.0: 0.10422094841063054, 9.0: 0.10422094841063054, 10.0: 0.10422094841063054, 11.0: 0.10422094841063054, 12.0: 0.10422094841063054, 13.0: 0.10422094841063054, 14.0: 0.10422094841063054, 15.0: 0.10422094841063054, 16.0: 0.10422094841063054, 17.0: 0.10422094841063054, 18.0: 0.10422094841063054, 19.0: 0.10422094841063054, 20.0: 0.10422094841063054, 21.0: 0.10422094841063054, 22.0: 0.10422094841063054, 23.0: 0.10422094841063054, 24.0: 0.10422094841063054, 25.0: 0.10422094841063054, 26.0: 0.10422094841063054, 27.0: 0.10422094841063054, 28.0: 0.10422094841063054, 29.0: 0.10422094841063054, 30.0: 0.10422094841063054, 31.0: 0.10422094841063054, 32.0: 0.10422094841063054, 34.0: 0.10422094841063054, 35.0: 0.10422094841063054, 37.0: 0.10422094841063054, 39.0: 0.10422094841063054, 40.0: 0.10422094841063054, 41.0: 0.10422094841063054, 42.0: 0.10422094841063054, 43.0: 0.10422094841063054, 44.0: 0.10422094841063054, 45.0: 0.10422094841063054, 46.0: 0.10422094841063054, 47.0: 0.10422094841063054, 48.0: 0.10422094841063054, 49.0: 0.10422094841063054, 50.0: 0.10422094841063054}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = {}\n",
        "maxx = test_dic[2.0]\n",
        "j = 0\n",
        "for i in range(50):\n",
        "  if i == 32 or i == 35 or i == 37:\n",
        "    #weights[float(i+1)] = 1\n",
        "    pass\n",
        "  else:\n",
        "    weights[float(j+1)] = maxx/test_dic[float(i+1)]\n",
        "  j += 1\n",
        "print(weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2V66xs1JxLm",
        "outputId": "02b23a01-7443-4ba4-fd75-3c40d8f5260b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1.0: 1.0, 2.0: 1.0, 3.0: 1.0, 4.0: 1.0, 5.0: 1.0, 6.0: 1.0, 7.0: 1.0, 8.0: 1.0, 9.0: 1.0, 10.0: 1.0, 11.0: 1.0, 12.0: 1.0, 13.0: 1.0, 14.0: 1.0, 15.0: 1.0, 16.0: 1.0, 17.0: 1.0, 18.0: 1.0, 19.0: 1.0, 20.0: 1.0, 21.0: 1.0, 22.0: 1.0, 23.0: 1.0, 24.0: 1.0, 25.0: 1.0, 26.0: 1.0, 27.0: 1.0, 28.0: 1.0, 29.0: 1.0, 30.0: 1.0, 31.0: 1.0, 32.0: 1.0, 34.0: 1.0, 35.0: 1.0, 37.0: 1.0, 39.0: 1.0, 40.0: 1.0, 41.0: 1.0, 42.0: 1.0, 43.0: 1.0, 44.0: 1.0, 45.0: 1.0, 46.0: 1.0, 47.0: 1.0, 48.0: 1.0, 49.0: 1.0, 50.0: 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_weights = dict(sorted(weights.items(), key=lambda item: item[1], reverse=True))\n",
        "print(sorted_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFcnkQ7rojAD",
        "outputId": "06826d66-63a2-4ff9-8b55-03af6570275e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1.0: 1.0, 2.0: 1.0, 3.0: 1.0, 4.0: 1.0, 5.0: 1.0, 6.0: 1.0, 7.0: 1.0, 8.0: 1.0, 9.0: 1.0, 10.0: 1.0, 11.0: 1.0, 12.0: 1.0, 13.0: 1.0, 14.0: 1.0, 15.0: 1.0, 16.0: 1.0, 17.0: 1.0, 18.0: 1.0, 19.0: 1.0, 20.0: 1.0, 21.0: 1.0, 22.0: 1.0, 23.0: 1.0, 24.0: 1.0, 25.0: 1.0, 26.0: 1.0, 27.0: 1.0, 28.0: 1.0, 29.0: 1.0, 30.0: 1.0, 31.0: 1.0, 32.0: 1.0, 34.0: 1.0, 35.0: 1.0, 37.0: 1.0, 39.0: 1.0, 40.0: 1.0, 41.0: 1.0, 42.0: 1.0, 43.0: 1.0, 44.0: 1.0, 45.0: 1.0, 46.0: 1.0, 47.0: 1.0, 48.0: 1.0, 49.0: 1.0, 50.0: 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2le9yrNLTeSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax = plt.subplot()\n",
        "plt.bar(range(len(count)), list(count.values()), align='center')\n",
        "plt.xticks(range(len(count)), list(count.keys()))\n",
        "plt.setp(ax.get_xticklabels(), rotation=90, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "Ibp5hz8QKp-N",
        "outputId": "4c207844-f329-4728-a32e-f03795a594f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.spy(X_train[510:750,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "XbUcydC9BAPL",
        "outputId": "6f1b26e3-b7f3-4a8c-ae74-433f74f1bfce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.lines.Line2D at 0x7fa986f2d110>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold"
      ],
      "metadata": {
        "id": "Q3Re_DVf-ZK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"model = LogisticRegression(random_state=0,max_iter=100)\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l2']\n",
        "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\"\"\""
      ],
      "metadata": {
        "id": "HtLx03Rv7xsd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "806882bc-ab14-4c67-c73a-e86ec64ea63c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model = LogisticRegression(random_state=0,max_iter=100)\\nsolvers = [\\'newton-cg\\', \\'lbfgs\\', \\'liblinear\\']\\npenalty = [\\'l2\\']\\nc_values = [100, 10, 1.0, 0.1, 0.01]\\ngrid = dict(solver=solvers,penalty=penalty,C=c_values)\\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\\ngrid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring=\\'accuracy\\',error_score=0)\\ngrid_result = grid_search.fit(X_train, y_train)\\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\\nmeans = grid_result.cv_results_[\\'mean_test_score\\']\\nstds = grid_result.cv_results_[\\'std_test_score\\']\\nparams = grid_result.cv_results_[\\'params\\']\\nfor mean, stdev, param in zip(means, stds, params):\\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=1000,multi_class = 'ovr',C=10)\n",
        "model.fit(X_train,y_train)\n",
        "y_pred = model.predict(X_train)\n",
        "acc3 = accuracy_score(y_train,y_pred)\n",
        "print(acc3)"
      ],
      "metadata": {
        "id": "ftlPHKnGUKL-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "60a7e04e-aa97-485e-d27b-573b5b7cca0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-e048188302f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0macc3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = model.predict(X_test)\n",
        "acc3 = accuracy_score(y_test,y_pred_test)\n",
        "print(acc3)"
      ],
      "metadata": {
        "id": "p4_7BRk6Ozqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=5000,multi_class = 'ovr',C=10,class_weight='balanced')\n",
        "print(X_train.shape,y_train.shape)\n",
        "model.fit(X_train,y_train)\n",
        "y_pred = model.predict_proba(X_train)\n",
        "print(y_pred.shape)\n",
        "#y_pred = y_pred[:,:5]\n",
        "#print(y_pred.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPsglw7xCzA2",
        "outputId": "501362ee-96c6-4e08-ae16-268e728c1c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7500, 225) (7500,)\n",
            "(7500, 47)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dic = {0:12,1:13,2:50,3:5,4:56,5:25,6:99,7:1,8:16}\n",
        "dic = dict(sorted(dic.items(), key=lambda item: item[1], reverse=True))\n",
        "for i in dic:\n",
        "  print(i,dic[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZnFChPLMKru",
        "outputId": "c1c32f0e-8759-4129-ef33-58b78079b879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 99\n",
            "4 56\n",
            "2 50\n",
            "5 25\n",
            "8 16\n",
            "1 13\n",
            "0 12\n",
            "3 5\n",
            "7 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def topFive(dic):\n",
        "  res = []\n",
        "  dic = dict(sorted(dic.items(), key=lambda item: item[1], reverse=True))\n",
        "  c = 5\n",
        "  for i in dic:\n",
        "    if c == 0:\n",
        "      break\n",
        "    res.append(i)\n",
        "    c -= 1\n",
        "  return np.array(res)"
      ],
      "metadata": {
        "id": "J4g-X2amIXHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_fin = []\n",
        "for y in y_pred:\n",
        "  j = 0\n",
        "  y_pred_tmp = []\n",
        "  for i in range(50):\n",
        "    if i == 32 or i == 35 or i ==  37:\n",
        "      y_pred_tmp.append(0)\n",
        "    else:\n",
        "      y_pred_tmp.append(y[j])\n",
        "      j += 1\n",
        "  y_pred_fin.append(y_pred_tmp)\n",
        "y_pred_fin = np.array(y_pred_fin)\n",
        "print(y_pred_fin.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kinZtp0DDQfK",
        "outputId": "f5c31198-d6b4-455a-8d06-cbcad305a7e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7500, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "y_dic = {}\n",
        "for i in range(len(y_pred)):\n",
        "  y_dic[i+1] = y_pred[i]\n",
        "print(y_dic)\n",
        "\"\"\"\n",
        "##\n",
        "res = []\n",
        "for y in y_pred_fin:\n",
        "  y_dic = {}\n",
        "  for i in range(50):\n",
        "      y_dic[i+1] = y[i]\n",
        "  r = topFive(y_dic)\n",
        "  res.append(r)\n",
        "res = np.array(res)\n",
        "print(res.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDd4mZHfNK9_",
        "outputId": "5b1590bd-da8d-4c0a-e6c9-6efca9d002c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7500, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test"
      ],
      "metadata": {
        "id": "XcqGo4aLK_iG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = model.predict_proba(X_test)\n",
        "y_pred_fin = []\n",
        "for y in y_pred_test:\n",
        "  j = 0\n",
        "  y_pred_tmp = []\n",
        "  for i in range(50):\n",
        "    if i == 32 or i == 35 or i ==  37:\n",
        "      y_pred_tmp.append(0)\n",
        "    else:\n",
        "      y_pred_tmp.append(y[j])\n",
        "      j += 1\n",
        "  y_pred_fin.append(y_pred_tmp)\n",
        "y_pred_fin = np.array(y_pred_fin)\n",
        "print(y_pred_fin.shape)\n",
        "res = []\n",
        "for y in y_pred_fin:\n",
        "  y_dic = {}\n",
        "  for i in range(50):\n",
        "      y_dic[i+1] = y[i]\n",
        "  r = topFive(y_dic)\n",
        "  res.append(r)\n",
        "res = np.array(res)\n",
        "print(res.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG8byT92K8Hp",
        "outputId": "502bade9-bb70-4c39-dd4c-56c6bb5bf895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2500, 50)\n",
            "(2500, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time as tm\n",
        "import numpy as np\n",
        "\n",
        "# This file is intended to demonstrate how we would evaluate your codeP\n",
        "# The data loader needs to know how many feature dimensions are there\n",
        "dictSize = 225\n",
        "#(X, y) = loadData( \"train\", dictSize = dictSize )\n",
        "X = X_test\n",
        "y = y_test\n",
        "# Get error class predictions from predict.py and time the thing\n",
        "tic = tm.perf_counter()\n",
        "#yPred = findErrorClass( X, 5 )\n",
        "yPred = res\n",
        "toc = tm.perf_counter()\n",
        "print('y.shape : ',y.shape,'yPred.shape : ',yPred.shape)\n",
        "print( \"Total time taken is %.6f seconds \" % (toc - tic) )\n",
        "\n",
        "preck = getPrecAtK( y, yPred, 5 )\n",
        "# The macro precision code takes a bit longer to execute due to the for loop over labels\n",
        "mpreck = getMPrecAtK( y, yPred, 5 )\n",
        "\n",
        "# According to our definitions, both prec@k and mprec@k should go up as k goes up i.e. for your\n",
        "# method, prec@i > prec@j if i > j and mprec@i > mprec@j if i > j. See the assignment description\n",
        "# to convince yourself why this must be the case.\n",
        "\n",
        "print( \"prec@1: %0.3f\" % preck[0], \"prec@3: %0.3f\" % preck[2], \"prec@5: %0.3f\" % preck[4] )\n",
        "# Dont be surprised if mprec is small -- it is hard to do well on rare error classes\n",
        "print( \"mprec@1: %0.3e\" % mpreck[0], \"mprec@3: %0.3e\" % mpreck[2], \"mprec@5: %0.3e\" % mpreck[4] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux1QtsH6PHDa",
        "outputId": "576891a5-7487-4a3f-bdbc-cd539483cf0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y.shape :  (2500,) yPred.shape :  (2500, 5)\n",
            "Total time taken is 0.000079 seconds \n",
            "prec@1: 0.730 prec@3: 0.928 prec@5: 0.958\n",
            "mprec@1: 5.873e-01 mprec@3: 8.509e-01 mprec@5: 8.954e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Training using balanced\n",
        "y.shape :  (7500,) yPred.shape :  (7500, 5)\n",
        "Total time taken is 0.000051 seconds\n",
        "prec@1: 0.790 prec@3: 0.967 prec@5: 0.986\n",
        "mprec@1: 7.761e-01 mprec@3: 9.904e-01 mprec@5: 9.975e-01\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gYCS_Cs5CjBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Testing using balanced\n",
        "y.shape :  (2500,) yPred.shape :  (2500, 5)\n",
        "Total time taken is 0.000052 seconds\n",
        "prec@1: 0.725 prec@3: 0.925 prec@5: 0.961\n",
        "mprec@1: 5.589e-01 mprec@3: 8.026e-01 mprec@5: 8.506e-01\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Hjg-mD-zLa-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Testing using wts\n",
        "y.shape :  (2500,) yPred.shape :  (2500, 5)\n",
        "Total time taken is 0.000040 seconds\n",
        "prec@1: 0.599 prec@3: 0.878 prec@5: 0.934\n",
        "mprec@1: 6.402e-01 mprec@3: 8.176e-01 mprec@5: 8.495e-01\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Sd_2kRDD0gG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XIdpoxruG9ek"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}